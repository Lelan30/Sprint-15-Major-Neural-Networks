### Apply an Autoencoder to a Basic Information Retrieval Problem ###

## Follow-Along ##
# Imports
from keras.datasets import mnist
from keras.layers import Input, Dense, Flatten
from keras.models import Model
from sklearn.neighbors import NearestNeighbors
import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Repeat Steps from previously trained model
(X_train, _), (X_test, _) = mnist.load_data()

X_train = X_train.astype('float32')/255
X_test = X_test.astype('float32')/255

X_train = X_train.reshape(len(X_train), np.prod(X_train.shape[1:]))
X_test = X_test.reshape(len(X_test), np.prod(X_test.shape[1:]))

print(X_train.shape)
print(X_test.shape)

input_img = Input(shape=(784,))

# Create simple autoencoder

# the size of our encoder representations
# 32 floats -> compression of factor 24.5, input is 784 floats
encoding_dim = 32

# 'encoded' is the encoded representation on input
encoded = Dense(784, activation='relu')(input_img)

#'decoded' os the lossy reconstruction of the input
decoded = Dense(784, activation='sigmoid')(encoded)

# This model maps an input to its recontruction
autoencoder = Model(input_img, decoded)

# This model maps an input to its encoded representation
encoder = Model(input_img, encoded)

# Compile model
autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Fit model
autoencoder.fit(X_train, X_train,
                epochs=10,
                batch_size=256,
                validation_data=(X_test, X_test))

## Retieve Images ##
# Import tensorflow as tf

#encoded = tf.keras.layers.Flatten()(encoded)

encoder = Model(input_img, encoded)

encoded_imgs = encoder.predict(X_train)

# Plot
# import matplotlib.pyplot as plt

# Look up an image that corresponds to this code
query = 34534

plt.imshow(X_train[query].reshape(28, 28));

'''
output:

We have an 8!
'''

# use the encoder model to create the encoded representaion
query_encoding = encoder.predict(np.expand_dims(X_train[query],0))

# Use the nearest neighbors algorith to look up images
# that have the closest representation

# from sklearn.neighbors import NearestNeighbors

# instantiate
nn = NearestNeighbors(n_neighbors=5, algorithm='ball_tree')
nn.fit(encoded_imgs)

# Find the result from query encoding
results = nn.kneighbors(query_encoding)

# Select and plot the first of the images retiieved
results_loc = results[1][0][1:]
plt.imshow(X_train[results_loc[1]].reshape(28,28));

